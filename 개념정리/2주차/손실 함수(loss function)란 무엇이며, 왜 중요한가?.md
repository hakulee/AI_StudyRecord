# 손실함수란 (Loss Function)
-  손실 함수의 주요 목적은 모델이 얼마나 잘못 예측하고 있는지를 측정하는 것이다. 이 수치가 작을수록 모델의 예측 정확도는 높아지게된다. 모델 학습 과정에서 알고리즘은 지속적으로 이 손실 값을 최소화하려 노력하며, 이를 통해 점진적으로 더 정확한 예측을 할 수 있게 된다.

# 주요 손실 함수
- **평균 제곱 오차(Mean Squared Error, MSE)**  
  MSE는 예측값과 실제값 사이의 차이를 제곱하여 평균을 계산한다. 오차를 제곱을 하여 계산하기 때문에 큰 오차에 대하서는 더 크게 반응한다. (값이 작을수록 좋음)

- **절대 평균 오차(Mean Absolute Error, MAE)**  
  예측값과 실제값의 차이를 절댓값으로 측정한 평균 오차이다. MSE보다 이상치(outlier)에 덜 민감합니다. (값이 0에 가까울수록 좋음)

- **교차 엔트로피(Cross-Entropy)**  
  손실 함수는 분류 문제에 최적화되어 있다. 특히 로지스틱 회귀와 신경망에서 효과적으로, 확률 분포 간의 차이를 측정합니다. 분류 모델에서 예측 확률의 불확실성을 정확하게 평가할 수 있다.

# 손실함수가 중요한 이유
- 손실 함수는 머신러닝 모델 최적화의 핵심 메커니즘이다. 최적화 알고리즘은 손실 함수의 값을 최소화하는 방향으로 모델의 파라미터를 조정함으로써 예측 성능을 향상시킨다.

- 또한, 과적합과 과소적합 문제 해결에서 적절한 손실 함수 선택은 모델이 훈련 데이터에 지나치게 맞추거나 일반화 능력을 상실하는 것을 방지한다. 따라서, 데이터의 특성에 맞는 손실 함수 선택은 모델 성능의 핵심이라고 할 수 있다.



> 손실함수 (Loss Function) = 오차함수(Error Function)  
>  - “하나”에 대한 오차를 계산하는 함수
>
> 비용함수 (Cost Function)  
>  - 하나 단위의 오차를 합치는 함수
