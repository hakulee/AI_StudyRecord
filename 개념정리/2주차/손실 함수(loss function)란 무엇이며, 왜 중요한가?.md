# :book:손실함수란 (Loss Function)
-  손실 함수의 주요 목적은 모델이 얼마나 잘못 예측하고 있는지를 측정하는 것이다. 이 수치가 작을수록 모델의 예측 정확도는 높아지게된다. 모델 학습 과정에서 알고리즘은 지속적으로 이 손실 값을 최소화하려 노력하며, 이를 통해 점진적으로 더 정확한 예측을 할 수 있게 된다.

# :mag_right:	주요 손실 함수
- **평균 제곱 오차(Mean Squared Error, MSE)**  
  MSE는 예측값과 실제값 사이의 차이를 제곱하여 평균을 계산한다. 오차를 제곱을 하여 계산하기 때문에 큰 오차에 대하서는 더 크게 반응한다. (값이 작을수록 좋음)

- **절대 평균 오차(Mean Absolute Error, MAE)**  
  예측값과 실제값의 차이를 절댓값으로 측정한 평균 오차이다. MSE보다 이상치(outlier)에 덜 민감합니다. (값이 0에 가까울수록 좋음)

- **교차 엔트로피(Cross-Entropy)**  
  손실 함수는 분류 문제에 최적화되어 있다. 특히 로지스틱 회귀와 신경망에서 효과적으로, 확률 분포 간의 차이를 측정합니다. 분류 모델에서 예측 확률의 불확실성을 정확하게 평가할 수 있다.

# :mag_right:	손실함수가 중요한 이유
- 손실 함수는 모델이 어떻게 성능을 발휘하고 있는지를 정량적으로 측정하는 역할을 한다. 모델이 학습 과정에서 얼마나 잘 또는 못하고 있는지를 스스로 판단하고 성능을 개선해 나갈수 있는 방향을 제시한다.
- 최적화 과정에서 값을 최소화하는 방향으로 모델의 파라미터를 조정함으로써 예측 성능을 향상시킬 수 있다.
- 모델이 훈련 데이터에 지나치게 맞추거나 일반화 능력을 상실하는 것을 방지함으로써 데이터의 특성에 맞는 손실 함수 선택은 모델 성능의 핵심이라고 할 수 있다.
